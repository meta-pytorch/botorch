{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer Learning Stack Demo\n",
        "\n",
        "This notebook demonstrates the models and functionality introduced across the first five diffs in the transfer learning refactoring stack:\n",
        "\n",
        "| # | Diff | What it introduces |\n",
        "|---|------|--------------------|\n",
        "| 1 | D92844568 | `FullyBayesianMultiTaskGP` as public API + Ax downstream |\n",
        "| 2 | D92844565 | `SaasFullyBayesianMultiTaskGP` as thin subclass of the new base |\n",
        "| 3 | D92844566 | Generalized internals — any `PyroModel(is_multitask=True)` works |\n",
        "| 4 | D92844567 | `is_multitask` kwarg on `PyroModel` base class |\n",
        "| 5 | D92836693 | `HeterogeneousMTGP` with inferred noise (`HadamardGaussianLikelihood`) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "output": {
          "id": 1701611334555256,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports OK\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.fit import fit_fully_bayesian_model_nuts\n",
        "from botorch.models.fully_bayesian import (\n",
        "    MaternPyroModel,\n",
        "    SaasPyroModel,\n",
        ")\n",
        "from botorch.models.fully_bayesian_multitask import (\n",
        "    FullyBayesianMultiTaskGP,\n",
        "    SaasFullyBayesianMultiTaskGP,\n",
        ")\n",
        "from botorch.models.heterogeneous_mtgp import HeterogeneousMTGP\n",
        "\n",
        "NUM_SAMPLES = 16\n",
        "WARMUP = 32\n",
        "THINNING = 1\n",
        "\n",
        "print(\"Imports OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Shared synthetic data\n",
        "\n",
        "Generate a simple 2-task dataset with 3 input features. Task 0 is a shifted sinusoid, task 1 is a linear function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "output": {
          "id": 1291867136109999,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_X shape: torch.Size([40, 4])\n",
            "train_Y shape: torch.Size([40, 1])\n",
            "test_X shape:  torch.Size([5, 4])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "d = 3  # input dimension\n",
        "n_per_task = 20\n",
        "\n",
        "# Task 0 data\n",
        "X0 = torch.rand(n_per_task, d)\n",
        "Y0 = torch.sin(X0.sum(dim=-1, keepdim=True)) + 0.1 * torch.randn(n_per_task, 1)\n",
        "i0 = torch.zeros(n_per_task, 1)\n",
        "\n",
        "# Task 1 data\n",
        "X1 = torch.rand(n_per_task, d)\n",
        "Y1 = X1.sum(dim=-1, keepdim=True) + 0.1 * torch.randn(n_per_task, 1)\n",
        "i1 = torch.ones(n_per_task, 1)\n",
        "\n",
        "# Combined training data with task feature as last column\n",
        "train_X = torch.cat([torch.cat([X0, i0], dim=-1), torch.cat([X1, i1], dim=-1)])\n",
        "train_Y = torch.cat([Y0, Y1])\n",
        "\n",
        "# Known observation noise\n",
        "train_Yvar = 0.01 * torch.ones_like(train_Y)\n",
        "\n",
        "# Test points for task 0\n",
        "test_X = torch.cat([torch.rand(5, d), torch.zeros(5, 1)], dim=-1)\n",
        "\n",
        "print(f\"train_X shape: {train_X.shape}\")\n",
        "print(f\"train_Y shape: {train_Y.shape}\")\n",
        "print(f\"test_X shape:  {test_X.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. `SaasFullyBayesianMultiTaskGP` — the SAAS subclass (Diffs 1 + 2)\n",
        "\n",
        "The existing `SaasFullyBayesianMultiTaskGP` now inherits from the new public `FullyBayesianMultiTaskGP` base and defaults to `SaasPyroModel(is_multitask=True)`. All existing behavior is preserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "output": {
          "id": 803591449416924,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 260210 12:34:24 autoreload:1553] The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/meta-pytorch/botorch/discussions/1444\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "super(type, obj): obj must be an instance or subtype of type",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n",
            "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The classic SAAS multi-task GP — unchanged API\u001b[39;00m\n",
            "\u001b[0;32m----> 2\u001b[0m model_saas \u001b[38;5;241m=\u001b[39m SaasFullyBayesianMultiTaskGP\u001b[49m(\u001b[49m\n",
            "\u001b[1;32m      3\u001b[0m     \u001b[49mtrain_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrain_X\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m      4\u001b[0m     \u001b[49mtrain_Y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrain_Y\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m      5\u001b[0m     \u001b[49mtrain_Yvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrain_Yvar\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m      6\u001b[0m     \u001b[49mtask_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m,\u001b[49m\n",
            "\u001b[1;32m      7\u001b[0m )\u001b[49m\n",
            "\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Verify it is a subclass of the new public base\u001b[39;00m\n",
            "\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_saas, FullyBayesianMultiTaskGP)\n",
            "\n",
            "File \u001b[0;32m/data/sandcastle/boxes/fbsource/fbcode/pytorch/botorch/botorch/models/fully_bayesian_multitask.py:378\u001b[0m, in \u001b[0;36mSaasFullyBayesianMultiTaskGP.__init__\u001b[0;34m(self, train_X, train_Y, task_feature, train_Yvar, output_tasks, rank, all_tasks, outcome_transform, input_transform, pyro_model, validate_task_values)\u001b[0m\n",
            "\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pyro_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;32m    377\u001b[0m     pyro_model \u001b[38;5;241m=\u001b[39m SaasPyroModel(is_multitask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m(\u001b[49m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m(\u001b[49m\n",
            "\u001b[1;32m    379\u001b[0m     \u001b[49mtrain_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrain_X\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    380\u001b[0m     \u001b[49mtrain_Y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrain_Y\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    381\u001b[0m     \u001b[49mtask_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtask_feature\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    382\u001b[0m     \u001b[49mtrain_Yvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrain_Yvar\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    383\u001b[0m     \u001b[49moutput_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49moutput_tasks\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    384\u001b[0m     \u001b[49mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mrank\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    385\u001b[0m     \u001b[49mall_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mall_tasks\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    386\u001b[0m     \u001b[49moutcome_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49moutcome_transform\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    387\u001b[0m     \u001b[49minput_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49minput_transform\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    388\u001b[0m     \u001b[49mpyro_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mpyro_model\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    389\u001b[0m     \u001b[49mvalidate_task_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mvalidate_task_values\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    390\u001b[0m \u001b[49m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m/data/sandcastle/boxes/fbsource/fbcode/pytorch/botorch/botorch/models/fully_bayesian_multitask.py:130\u001b[0m, in \u001b[0;36mFullyBayesianMultiTaskGP.__init__\u001b[0;34m(self, train_X, train_Y, task_feature, train_Yvar, output_tasks, rank, all_tasks, outcome_transform, input_transform, pyro_model, validate_task_values)\u001b[0m\n",
            "\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_Yvar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Clamp after transforming\u001b[39;00m\n",
            "\u001b[1;32m    128\u001b[0m     train_Yvar \u001b[38;5;241m=\u001b[39m train_Yvar\u001b[38;5;241m.\u001b[39mclamp(MIN_INFERRED_NOISE_LEVEL)\n",
            "\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m(\u001b[49m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m(\u001b[49m\n",
            "\u001b[1;32m    131\u001b[0m     \u001b[49mtrain_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrain_X\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    132\u001b[0m     \u001b[49mtrain_Y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrain_Y\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    133\u001b[0m     \u001b[49mtrain_Yvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtrain_Yvar\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    134\u001b[0m     \u001b[49mtask_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mtask_feature\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    135\u001b[0m     \u001b[49moutput_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49moutput_tasks\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    136\u001b[0m     \u001b[49mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mrank\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    137\u001b[0m     \u001b[49m\u001b[38;5;66;43;03m# We already transformed the data above, this avoids applying the\u001b[39;49;00m\n",
            "\u001b[1;32m    138\u001b[0m     \u001b[49m\u001b[38;5;66;43;03m# default ``Standardize`` transform twice. As outcome_transform is\u001b[39;49;00m\n",
            "\u001b[1;32m    139\u001b[0m     \u001b[49m\u001b[38;5;66;43;03m# set on ``self`` below, it will be applied to the posterior in the\u001b[39;49;00m\n",
            "\u001b[1;32m    140\u001b[0m     \u001b[49m\u001b[38;5;66;43;03m# ``posterior`` method of ``MultiTaskGP``.\u001b[39;49;00m\n",
            "\u001b[1;32m    141\u001b[0m     \u001b[49moutcome_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m,\u001b[49m\n",
            "\u001b[1;32m    142\u001b[0m     \u001b[49mall_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mall_tasks\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    143\u001b[0m     \u001b[49mvalidate_task_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mvalidate_task_values\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    144\u001b[0m \u001b[49m)\u001b[49m\n",
            "\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(train_X)\n",
            "\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m~/.bento/kernels/bento_kernel_ae/5889/bento_kernel_ae_binary-inplace#link-tree/parsh/autoreload/autoreload.py:1563\u001b[0m, in \u001b[0;36mModuleReloader._update_class.<locals>._patched__init__\u001b[0;34m(cls_instance, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dump_autoreload_error \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mdump_autoreload_error:\n",
            "\u001b[1;32m   1556\u001b[0m     dump_autoreload_error(\n",
            "\u001b[1;32m   1557\u001b[0m         e,\n",
            "\u001b[1;32m   1558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautoreload.warning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m   1561\u001b[0m         ),\n",
            "\u001b[1;32m   1562\u001b[0m     )\n",
            "\u001b[0;32m-> 1563\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\n",
            "File \u001b[0;32m~/.bento/kernels/bento_kernel_ae/5889/bento_kernel_ae_binary-inplace#link-tree/parsh/autoreload/autoreload.py:1553\u001b[0m, in \u001b[0;36mModuleReloader._update_class.<locals>._patched__init__\u001b[0;34m(cls_instance, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1551\u001b[0m             new\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(cls_instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;32m-> 1553\u001b[0m         orig__init__\u001b[49m(\u001b[49mcls_instance\u001b[49m,\u001b[49m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49margs\u001b[49m,\u001b[49m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49mkwargs\u001b[49m)\u001b[49m\n",
            "\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[1;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dump_autoreload_error \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mdump_autoreload_error:\n",
            "\n",
            "File \u001b[0;32m/data/sandcastle/boxes/fbsource/fbcode/pytorch/botorch/botorch/models/multitask.py:284\u001b[0m, in \u001b[0;36mMultiTaskGP.__init__\u001b[0;34m(self, train_X, train_Y, task_feature, train_Yvar, mean_module, covar_module, likelihood, task_covar_prior, output_tasks, rank, all_tasks, outcome_transform, input_transform, validate_task_values)\u001b[0m\n",
            "\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_idxr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_non_task_features)\n",
            "\u001b[1;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_idxr[task_feature:] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# exclude task feature\u001b[39;00m\n",
            "\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n",
            "\u001b[1;32m    285\u001b[0m     train_inputs\u001b[38;5;241m=\u001b[39mtrain_X, train_targets\u001b[38;5;241m=\u001b[39mtrain_Y, likelihood\u001b[38;5;241m=\u001b[39mlikelihood\n",
            "\u001b[1;32m    286\u001b[0m )\n",
            "\u001b[1;32m    287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_module \u001b[38;5;241m=\u001b[39m mean_module \u001b[38;5;129;01mor\u001b[39;00m MultitaskMean(\n",
            "\u001b[1;32m    288\u001b[0m     base_means\u001b[38;5;241m=\u001b[39mConstantMean(batch_shape\u001b[38;5;241m=\u001b[39mtrain_X\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]),\n",
            "\u001b[1;32m    289\u001b[0m     num_tasks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_tasks,\n",
            "\u001b[1;32m    290\u001b[0m )\n",
            "\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m covar_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\n",
            "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
          ]
        },
        {
          "data": {
            "application/notebook-debug-button": "{\n\t\"notebookUri\": \"file:///data/sandcastle/boxes/fbsource/fbcode/pytorch/botorch/notebooks/transfer_learning_stack_demo.ipynb\"\n}"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# The classic SAAS multi-task GP — unchanged API\n",
        "model_saas = SaasFullyBayesianMultiTaskGP(\n",
        "    train_X=train_X,\n",
        "    train_Y=train_Y,\n",
        "    train_Yvar=train_Yvar,\n",
        "    task_feature=-1,\n",
        ")\n",
        "\n",
        "# Verify it is a subclass of the new public base\n",
        "assert isinstance(model_saas, FullyBayesianMultiTaskGP)\n",
        "print(f\"SaasFullyBayesianMultiTaskGP is subclass of FullyBayesianMultiTaskGP: True\")\n",
        "print(f\"PyroModel type: {type(model_saas.pyro_model).__name__}\")\n",
        "\n",
        "fit_fully_bayesian_model_nuts(\n",
        "    model_saas,\n",
        "    warmup_steps=WARMUP,\n",
        "    num_samples=NUM_SAMPLES,\n",
        "    thinning=THINNING,\n",
        "    disable_progbar=True,\n",
        ")\n",
        "\n",
        "posterior_saas = model_saas.posterior(test_X)\n",
        "print(f\"Posterior mean shape: {posterior_saas.mean.shape}\")\n",
        "print(f\"Median lengthscale:   {model_saas.median_lengthscale}\")\n",
        "print(\"✅ SaasFullyBayesianMultiTaskGP works as before\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. `FullyBayesianMultiTaskGP` with `MaternPyroModel` (Diffs 3 + 4)\n",
        "\n",
        "The refactored base class now accepts *any* `PyroModel(is_multitask=True)`. Here we use `MaternPyroModel` — a simpler prior without SAAS sparsity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the public base class directly with a non-SAAS PyroModel\n",
        "model_matern = FullyBayesianMultiTaskGP(\n",
        "    train_X=train_X,\n",
        "    train_Y=train_Y,\n",
        "    train_Yvar=train_Yvar,\n",
        "    task_feature=-1,\n",
        "    pyro_model=MaternPyroModel(is_multitask=True),\n",
        ")\n",
        "\n",
        "print(f\"PyroModel type: {type(model_matern.pyro_model).__name__}\")\n",
        "print(f\"is_multitask:   {model_matern.pyro_model.is_multitask}\")\n",
        "\n",
        "fit_fully_bayesian_model_nuts(\n",
        "    model_matern,\n",
        "    warmup_steps=WARMUP,\n",
        "    num_samples=NUM_SAMPLES,\n",
        "    thinning=THINNING,\n",
        "    disable_progbar=True,\n",
        ")\n",
        "\n",
        "posterior_matern = model_matern.posterior(test_X)\n",
        "print(f\"Posterior mean shape: {posterior_matern.mean.shape}\")\n",
        "print(f\"Num MCMC samples:     {model_matern.num_mcmc_samples}\")\n",
        "print(\"✅ FullyBayesianMultiTaskGP + MaternPyroModel works\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. `FullyBayesianMultiTaskGP` with `SaasPyroModel` explicitly (Diff 3)\n",
        "\n",
        "We can also pass `SaasPyroModel(is_multitask=True)` explicitly to the base class — this is equivalent to using `SaasFullyBayesianMultiTaskGP` but demonstrates the generalized constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explicit SaasPyroModel passed to the base class\n",
        "model_explicit_saas = FullyBayesianMultiTaskGP(\n",
        "    train_X=train_X,\n",
        "    train_Y=train_Y,\n",
        "    train_Yvar=train_Yvar,\n",
        "    task_feature=-1,\n",
        "    pyro_model=SaasPyroModel(is_multitask=True),\n",
        ")\n",
        "\n",
        "print(f\"PyroModel type: {type(model_explicit_saas.pyro_model).__name__}\")\n",
        "\n",
        "fit_fully_bayesian_model_nuts(\n",
        "    model_explicit_saas,\n",
        "    warmup_steps=WARMUP,\n",
        "    num_samples=NUM_SAMPLES,\n",
        "    thinning=THINNING,\n",
        "    disable_progbar=True,\n",
        ")\n",
        "\n",
        "posterior_explicit = model_explicit_saas.posterior(test_X)\n",
        "print(f\"Posterior mean shape: {posterior_explicit.mean.shape}\")\n",
        "print(\"✅ FullyBayesianMultiTaskGP + explicit SaasPyroModel works\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Validation: `is_multitask=True` is enforced (Diff 4)\n",
        "\n",
        "Passing a single-task `PyroModel` to `FullyBayesianMultiTaskGP` should raise a clear error. Similarly, `set_inputs` with `is_multitask=True` and `task_feature=None` gives a helpful `ValueError`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4a. Verify that a non-multitask PyroModel is rejected\n",
        "rejected = False\n",
        "try:\n",
        "    FullyBayesianMultiTaskGP(\n",
        "        train_X=train_X,\n",
        "        train_Y=train_Y,\n",
        "        train_Yvar=train_Yvar,\n",
        "        task_feature=-1,\n",
        "        pyro_model=MaternPyroModel(is_multitask=False),  # Wrong!\n",
        "    )\n",
        "except ValueError as e:\n",
        "    rejected = True\n",
        "    print(f\"✅ Non-multitask PyroModel correctly rejected: {e}\")\n",
        "\n",
        "assert rejected, \"Should have raised ValueError\"\n",
        "\n",
        "# 4b. Verify that task_feature=None with is_multitask=True raises ValueError\n",
        "pm = MaternPyroModel(is_multitask=True)\n",
        "task_feature_rejected = False\n",
        "try:\n",
        "    pm.set_inputs(\n",
        "        train_X=train_X,\n",
        "        train_Y=train_Y,\n",
        "        train_Yvar=train_Yvar,\n",
        "        task_feature=None,  # Missing!\n",
        "    )\n",
        "except ValueError as e:\n",
        "    task_feature_rejected = True\n",
        "    print(f\"✅ Missing task_feature correctly rejected: {e}\")\n",
        "\n",
        "assert task_feature_rejected, \"Should have raised ValueError\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. `HeterogeneousMTGP` with inferred noise (Diff 5)\n",
        "\n",
        "Diff 5 (D92836693) adds support for `HeterogeneousMTGP` with inferred noise by using a `HadamardGaussianLikelihood`. We demonstrate this by constructing a model *without* specifying `train_Yvars`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Task 0: 3 features [0, 1, 2]\n",
        "X0_het = torch.rand(15, 3)\n",
        "Y0_het = torch.sin(X0_het.sum(-1, keepdim=True)) + 0.1 * torch.randn(15, 1)\n",
        "\n",
        "# Task 1: 2 features [0, 2] (different search space)\n",
        "X1_het = torch.rand(15, 2)\n",
        "Y1_het = X1_het.sum(-1, keepdim=True) + 0.1 * torch.randn(15, 1)\n",
        "\n",
        "feature_indices = [[0, 1, 2], [0, 2]]  # task 1 shares features 0 and 2\n",
        "full_feature_dim = 3\n",
        "\n",
        "# With known noise\n",
        "model_het_known = HeterogeneousMTGP(\n",
        "    train_Xs=[X0_het, X1_het],\n",
        "    train_Ys=[Y0_het, Y1_het],\n",
        "    train_Yvars=[0.01 * torch.ones(15, 1), 0.01 * torch.ones(15, 1)],\n",
        "    feature_indices=feature_indices,\n",
        "    full_feature_dim=full_feature_dim,\n",
        ")\n",
        "print(f\"HeterogeneousMTGP (known noise) likelihood: {type(model_het_known.likelihood).__name__}\")\n",
        "\n",
        "# With inferred noise (new in Diff 5)\n",
        "model_het_inferred = HeterogeneousMTGP(\n",
        "    train_Xs=[X0_het, X1_het],\n",
        "    train_Ys=[Y0_het, Y1_het],\n",
        "    train_Yvars=None,  # Infer noise!\n",
        "    feature_indices=feature_indices,\n",
        "    full_feature_dim=full_feature_dim,\n",
        ")\n",
        "print(f\"HeterogeneousMTGP (inferred noise) likelihood: {type(model_het_inferred.likelihood).__name__}\")\n",
        "\n",
        "# Test posterior for the inferred-noise model\n",
        "test_X_het = torch.rand(5, 3)  # task 0 features only\n",
        "posterior_het = model_het_inferred.posterior(test_X_het)\n",
        "print(f\"Posterior mean shape: {posterior_het.mean.shape}\")\n",
        "print(\"✅ HeterogeneousMTGP with inferred noise (HadamardGaussianLikelihood) works\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "All five diffs are exercised:\n",
        "\n",
        "| Diff | Model / Feature | Status |\n",
        "|------|-----------------|--------|\n",
        "| D92844568 | `FullyBayesianMultiTaskGP` as public API | ✅ |\n",
        "| D92844565 | `SaasFullyBayesianMultiTaskGP` as subclass | ✅ |\n",
        "| D92844566 | Generalized internals (`MaternPyroModel`, `SaasPyroModel`) | ✅ |\n",
        "| D92844567 | `is_multitask` on `PyroModel` + validation | ✅ |\n",
        "| D92836693 | `HeterogeneousMTGP` inferred noise | ✅ |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ae",
      "language": "python",
      "name": "bento_kernel_ae"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
