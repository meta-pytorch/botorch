{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Implementation of Scalable Constrained Bayesian Optimization (SCBO)\n",
    "### https://doi.org/10.48550/arxiv.2002.08526\n",
    "### Code copied from BoTorch TuRBO Tutorial (https://botorch.org/tutorials/turbo_1) and modified to implement SCBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.test_functions import Ackley\n",
    "from botorch.utils.transforms import unnormalize\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "\n",
    "# Constrained Max Posterior Sampling Implementation\n",
    "from botorch.generation.sampling import ConstrainedMaxPosteriorSampling\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration with 20-dimensional Ackley function and Two Simple Constraint Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = Ackley(dim=20, negate=True).to(dtype=dtype, device=device)\n",
    "fun.bounds[0, :].fill_(-5)\n",
    "fun.bounds[1, :].fill_(10)\n",
    "dim = fun.dim\n",
    "lb, ub = fun.bounds\n",
    "\n",
    "batch_size = 4\n",
    "n_init = 2 * dim\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "def eval_objective(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return fun(unnormalize(x, fun.bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple constraint functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use two constraints functions c1, c2 \n",
    "# We want to find solutions which maximize the above objective subject tot he constraint that \n",
    "# c1(x) <= 0 and c2(x) <= 0 \n",
    "# Assume c1, c2 have same bounds as fun above \n",
    "\n",
    "def c1(x): # Equivalent to enforcing that x[0] >= 0\n",
    "    return -x[0] \n",
    "\n",
    "def c2(x): # Equivalent to enforcing that x[1] >= 0\n",
    "    return -x[1] \n",
    "\n",
    "# Note that the above constraints are very simple functions,\n",
    "# the point being that SCBO could be applied in the same way if \n",
    "# c1, c2 were actually complex black-box functions \n",
    "\n",
    "def eval_c1(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return c1(unnormalize(x, fun.bounds))\n",
    "\n",
    "def eval_c2(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return c2(unnormalize(x, fun.bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TuRBO State "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TurboState(dim=20, batch_size=4, length=0.8, length_min=0.0078125, length_max=1.6, failure_counter=0, failure_tolerance=5, success_counter=0, success_tolerance=10, best_value=-inf, restart_triggered=False)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class TurboState:\n",
    "    dim: int\n",
    "    batch_size: int\n",
    "    length: float = 0.8\n",
    "    length_min: float = 0.5 ** 7\n",
    "    length_max: float = 1.6\n",
    "    failure_counter: int = 0\n",
    "    failure_tolerance: int = float(\"nan\")  # Note: Post-initialized\n",
    "    success_counter: int = 0\n",
    "    success_tolerance: int = 10  # Note: The original paper uses 3\n",
    "    best_value: float = -float(\"inf\")\n",
    "    restart_triggered: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.failure_tolerance = math.ceil(\n",
    "            max([4.0 / self.batch_size, float(self.dim) / self.batch_size])\n",
    "        )\n",
    "\n",
    "\n",
    "def update_state(state, Y_next):\n",
    "    if max(Y_next) > state.best_value + 1e-3 * math.fabs(state.best_value):\n",
    "        state.success_counter += 1\n",
    "        state.failure_counter = 0\n",
    "    else:\n",
    "        state.success_counter = 0\n",
    "        state.failure_counter += 1\n",
    "\n",
    "    if state.success_counter == state.success_tolerance:  # Expand trust region\n",
    "        state.length = min(2.0 * state.length, state.length_max)\n",
    "        state.success_counter = 0\n",
    "    elif state.failure_counter == state.failure_tolerance:  # Shrink trust region\n",
    "        state.length /= 2.0\n",
    "        state.failure_counter = 0\n",
    "\n",
    "    state.best_value = max(state.best_value, max(Y_next).item())\n",
    "    if state.length < state.length_min:\n",
    "        state.restart_triggered = True\n",
    "    return state\n",
    "\n",
    "state = TurboState(dim=dim, batch_size=batch_size)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Initial Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_points(dim, n_pts, seed=0):\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    X_init = sobol.draw(n=n_pts).to(dtype=dtype, device=device)\n",
    "    return X_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SCBO to generate batch of candidates that meet constraints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(\n",
    "    state,\n",
    "    model,  # GP model\n",
    "    X,  # Evaluated points on the domain [0, 1]^d\n",
    "    Y,  # Function values\n",
    "    batch_size,\n",
    "    n_candidates=None,  # Number of candidates for Thompson sampling\n",
    "    constraint_model=None\n",
    "):\n",
    "    assert X.min() >= 0.0 and X.max() <= 1.0 and torch.all(torch.isfinite(Y))\n",
    "    if n_candidates is None:\n",
    "        n_candidates = min(5000, max(2000, 200 * X.shape[-1]))\n",
    "\n",
    "    # Scale the TR to be proportional to the lengthscales\n",
    "    x_center = X[Y.argmax(), :].clone()\n",
    "    weights = model.covar_module.base_kernel.lengthscale.squeeze().detach()\n",
    "    weights = weights / weights.mean()\n",
    "    weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
    "    tr_lb = torch.clamp(x_center - weights * state.length / 2.0, 0.0, 1.0)\n",
    "    tr_ub = torch.clamp(x_center + weights * state.length / 2.0, 0.0, 1.0)\n",
    "\n",
    "    # Thompson Sampling w/ Constraints (SCBO) \n",
    "    dim = X.shape[-1]\n",
    "    sobol = SobolEngine(dim, scramble=True)\n",
    "    pert = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
    "    pert = tr_lb + (tr_ub - tr_lb) * pert\n",
    "\n",
    "    # Create a perturbation mask\n",
    "    prob_perturb = min(20.0 / dim, 1.0)\n",
    "    mask = (\n",
    "        torch.rand(n_candidates, dim, dtype=dtype, device=device)\n",
    "        <= prob_perturb\n",
    "    )\n",
    "    ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
    "    mask[ind, torch.randint(0, dim - 1, size=(len(ind),), device=device)] = 1\n",
    "\n",
    "    # Create candidate points from the perturbations and the mask        \n",
    "    X_cand = x_center.expand(n_candidates, dim).clone()\n",
    "    X_cand[mask] = pert[mask]\n",
    "\n",
    "    # Sample on the candidate points\n",
    "    constrained_thompson_sampling = ConstrainedMaxPosteriorSampling(model=model, constraint_model=constraint_model, replacement=False)\n",
    "    with torch.no_grad():  \n",
    "        X_next = constrained_thompson_sampling(X_cand, num_samples=batch_size)\n",
    "\n",
    "\n",
    "    return X_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.6854, device='cuda:0'),\n",
       " tensor(4.8509, device='cuda:0'),\n",
       " tensor(-9.8032, device='cuda:0'),\n",
       " tensor(4.7317, device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial data \n",
    "X_turbo = get_initial_points(dim, n_init)\n",
    "Y_turbo = torch.tensor(\n",
    "    [eval_objective(x) for x in X_turbo], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "C1_turbo = torch.tensor(\n",
    "    [eval_c1(x) for x in X_turbo], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "C2_turbo = torch.tensor(\n",
    "    [eval_c2(x) for x in X_turbo], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "C1_turbo.min(), C1_turbo.max(), C2_turbo.min(), C2_turbo.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of the suggested candidates met the constraints...\n",
      "44) Best value: -inf, TR length: 8.00e-01\n",
      "None of the suggested candidates met the constraints...\n",
      "48) Best value: -inf, TR length: 8.00e-01\n",
      "52) Best value: -1.24e+01, TR length: 8.00e-01\n",
      "56) Best value: -1.22e+01, TR length: 8.00e-01\n",
      "60) Best value: -1.13e+01, TR length: 8.00e-01\n",
      "64) Best value: -1.03e+01, TR length: 8.00e-01\n",
      "68) Best value: -1.03e+01, TR length: 8.00e-01\n",
      "72) Best value: -1.03e+01, TR length: 8.00e-01\n",
      "76) Best value: -1.03e+01, TR length: 8.00e-01\n",
      "80) Best value: -1.03e+01, TR length: 8.00e-01\n",
      "84) Best value: -1.03e+01, TR length: 4.00e-01\n",
      "88) Best value: -9.54e+00, TR length: 4.00e-01\n",
      "92) Best value: -9.34e+00, TR length: 4.00e-01\n",
      "96) Best value: -8.60e+00, TR length: 4.00e-01\n",
      "100) Best value: -8.03e+00, TR length: 4.00e-01\n",
      "104) Best value: -7.93e+00, TR length: 4.00e-01\n",
      "108) Best value: -7.93e+00, TR length: 4.00e-01\n",
      "112) Best value: -7.93e+00, TR length: 4.00e-01\n",
      "116) Best value: -7.93e+00, TR length: 4.00e-01\n",
      "120) Best value: -7.93e+00, TR length: 4.00e-01\n",
      "124) Best value: -7.93e+00, TR length: 2.00e-01\n",
      "128) Best value: -7.89e+00, TR length: 2.00e-01\n",
      "132) Best value: -7.11e+00, TR length: 2.00e-01\n",
      "136) Best value: -7.11e+00, TR length: 2.00e-01\n",
      "140) Best value: -7.11e+00, TR length: 2.00e-01\n",
      "144) Best value: -7.11e+00, TR length: 2.00e-01\n",
      "148) Best value: -7.11e+00, TR length: 2.00e-01\n",
      "152) Best value: -7.11e+00, TR length: 1.00e-01\n",
      "156) Best value: -7.11e+00, TR length: 1.00e-01\n",
      "160) Best value: -6.95e+00, TR length: 1.00e-01\n",
      "164) Best value: -6.95e+00, TR length: 1.00e-01\n",
      "168) Best value: -6.94e+00, TR length: 1.00e-01\n",
      "172) Best value: -6.82e+00, TR length: 1.00e-01\n",
      "176) Best value: -6.80e+00, TR length: 1.00e-01\n",
      "180) Best value: -6.72e+00, TR length: 1.00e-01\n",
      "184) Best value: -6.72e+00, TR length: 1.00e-01\n",
      "188) Best value: -6.71e+00, TR length: 1.00e-01\n",
      "192) Best value: -6.51e+00, TR length: 1.00e-01\n",
      "196) Best value: -6.51e+00, TR length: 1.00e-01\n",
      "200) Best value: -6.51e+00, TR length: 1.00e-01\n",
      "204) Best value: -6.22e+00, TR length: 1.00e-01\n",
      "208) Best value: -6.22e+00, TR length: 1.00e-01\n",
      "212) Best value: -6.22e+00, TR length: 1.00e-01\n",
      "216) Best value: -6.22e+00, TR length: 1.00e-01\n",
      "220) Best value: -6.22e+00, TR length: 1.00e-01\n",
      "224) Best value: -6.22e+00, TR length: 5.00e-02\n",
      "228) Best value: -6.22e+00, TR length: 5.00e-02\n",
      "232) Best value: -6.22e+00, TR length: 5.00e-02\n",
      "236) Best value: -6.22e+00, TR length: 5.00e-02\n",
      "240) Best value: -6.18e+00, TR length: 5.00e-02\n",
      "244) Best value: -6.18e+00, TR length: 5.00e-02\n",
      "248) Best value: -6.18e+00, TR length: 5.00e-02\n",
      "252) Best value: -6.18e+00, TR length: 5.00e-02\n",
      "256) Best value: -6.18e+00, TR length: 5.00e-02\n",
      "260) Best value: -6.18e+00, TR length: 2.50e-02\n",
      "264) Best value: -5.98e+00, TR length: 2.50e-02\n",
      "268) Best value: -5.96e+00, TR length: 2.50e-02\n",
      "272) Best value: -5.96e+00, TR length: 2.50e-02\n",
      "276) Best value: -5.96e+00, TR length: 2.50e-02\n",
      "280) Best value: -5.95e+00, TR length: 2.50e-02\n",
      "284) Best value: -5.95e+00, TR length: 2.50e-02\n",
      "288) Best value: -5.95e+00, TR length: 2.50e-02\n",
      "292) Best value: -5.95e+00, TR length: 2.50e-02\n",
      "296) Best value: -5.95e+00, TR length: 2.50e-02\n",
      "300) Best value: -5.95e+00, TR length: 1.25e-02\n",
      "304) Best value: -5.87e+00, TR length: 1.25e-02\n",
      "308) Best value: -5.87e+00, TR length: 1.25e-02\n",
      "312) Best value: -5.65e+00, TR length: 1.25e-02\n",
      "316) Best value: -5.65e+00, TR length: 1.25e-02\n",
      "320) Best value: -5.65e+00, TR length: 1.25e-02\n",
      "324) Best value: -5.65e+00, TR length: 1.25e-02\n",
      "328) Best value: -5.65e+00, TR length: 1.25e-02\n",
      "332) Best value: -5.65e+00, TR length: 6.25e-03\n"
     ]
    }
   ],
   "source": [
    "state = TurboState(dim, batch_size=batch_size)\n",
    "N_CANDIDATES = min(5000, max(2000, 200 * dim)) \n",
    "\n",
    " \n",
    "while not state.restart_triggered:  # Run until TuRBO converges\n",
    "    # Fit a GP model for objective \n",
    "    train_Y = (Y_turbo - Y_turbo.mean()) / Y_turbo.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        MaternKernel(nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0))\n",
    "    )\n",
    "    model = SingleTaskGP(X_turbo, train_Y, covar_module=covar_module, likelihood=likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    # Fit a GP model for C1 \n",
    "    train_C1 = (C1_turbo - C1_turbo.mean()) / C1_turbo.std()\n",
    "    c1_likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    c1_covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        MaternKernel(nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0))\n",
    "    )\n",
    "    c1_model = SingleTaskGP(X_turbo, train_C1, covar_module=c1_covar_module, likelihood=c1_likelihood)\n",
    "    c1_mll = ExactMarginalLogLikelihood(c1_model.likelihood, c1_model)\n",
    "\n",
    "    # Fit a GP model for C2 \n",
    "    train_C2 = (C2_turbo - C2_turbo.mean()) / C2_turbo.std()\n",
    "    c2_likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    c2_covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        MaternKernel(nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0))\n",
    "    )\n",
    "    c2_model = SingleTaskGP(X_turbo, train_C2, covar_module=c2_covar_module, likelihood=c2_likelihood)\n",
    "    c2_mll = ExactMarginalLogLikelihood(c2_model.likelihood, c2_model)\n",
    "\n",
    "    # Do the fitting and acquisition function optimization inside the Cholesky context\n",
    "    with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "        # Fit the models\n",
    "        fit_gpytorch_model(mll)\n",
    "        fit_gpytorch_model(c1_mll)\n",
    "        fit_gpytorch_model(c2_mll)\n",
    "    \n",
    "        # Create a batch\n",
    "        X_next = generate_batch(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            X=X_turbo,\n",
    "            Y=train_Y,\n",
    "            batch_size=batch_size,\n",
    "            n_candidates=N_CANDIDATES,\n",
    "            constraint_model=ModelListGP(c1_model, c2_model)    \n",
    "        )\n",
    "\n",
    "    Y_next = torch.tensor(\n",
    "        [eval_objective(x) for x in X_next], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1) \n",
    "\n",
    "    C1_next = torch.tensor(\n",
    "        [eval_c1(x) for x in X_next], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1) \n",
    "\n",
    "    C2_next = torch.tensor( \n",
    "        [eval_c2(x) for x in X_next], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1) \n",
    "\n",
    "    # Valid samples must have BOTH c1 <= 0 and c2 <= 0 \n",
    "    constraint_vals = torch.cat([C1_next, C2_next], dim=-1) \n",
    "    bool_tensor = constraint_vals <= 0 \n",
    "    bool_tensor = torch.all(bool_tensor, dim=-1).unsqueeze(-1) \n",
    "    Valid_Y_next = Y_next[bool_tensor] \n",
    "\n",
    "    # Update state only with VALID y_next... \n",
    "    if Valid_Y_next.numel() > 0:\n",
    "        state = update_state(state=state, Y_next=Valid_Y_next)\n",
    "    else:\n",
    "        print(\"None of the suggested candidates met the constraints...\")\n",
    "\n",
    "    # Append data\n",
    "    X_turbo = torch.cat((X_turbo, X_next), dim=0)\n",
    "    Y_turbo = torch.cat((Y_turbo, Y_next), dim=0)\n",
    "    C1_turbo = torch.cat((C1_turbo, C1_next), dim=0)\n",
    "    C2_turbo = torch.cat((C2_turbo, C2_next), dim=0)\n",
    "\n",
    "    # Print current status \n",
    "    print(\n",
    "        f\"{len(X_turbo)}) Best value: {state.best_value:.2e}, TR length: {state.length:.2e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With constraints, the best value we found is: -5.6503\n"
     ]
    }
   ],
   "source": [
    "#  Valid samples must have BOTH c1 <= 0 and c2 <= 0  \n",
    "constraint_vals = torch.cat([C1_turbo, C2_turbo], dim=-1) \n",
    "bool_tensor = constraint_vals <= 0 \n",
    "bool_tensor = torch.all(bool_tensor, dim=-1).unsqueeze(-1) \n",
    "Valid_Y = Y_turbo[bool_tensor] \n",
    "\n",
    "print(f\"With constraints, the best value we found is: {Valid_Y.max().item():.4f}\") "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9beb4c3e6521665a47c2b1e65f245d1b2309f4194f15ed6955f5e52622a9d29e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
