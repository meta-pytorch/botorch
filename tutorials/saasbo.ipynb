{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "501041cc-0473-4971-bff9-fd6e92e1eae4",
    "showInput": false
   },
   "source": [
    "## High-Dimensional sample-efficient Bayesian Optimization with SAASBO\n",
    "\n",
    "This tutorial shows how to use the Sparse Axis-Aligned Subspace Bayesian Optimization (SAASBO) \n",
    "method for high-dimensional Bayesian optimization [1]. SAASBO places strong priors on the \n",
    "inverse lengthscales to avoid overfitting in high-dimensional spaces. Specifically, SAASBO \n",
    "uses a hierarchical sparsity prior consisting of a global shrinkage parameter \n",
    "$\\tau \\sim \\mathcal{HC}(\\beta)$ and inverse lengthscales $\\rho_d \\sim \\mathcal{HC}(\\tau)$ \n",
    "for $d=1, \\ldots, D$, where $\\mathcal{HC}$ is the half-Cauchy distribution. \n",
    "While half-Cauchy priors favor values near zero they also have heavy tails, which allows the \n",
    "inverse lengthscales of the most important parameters to escape zero. To perform inference in the \n",
    "SAAS model we use Hamiltonian Monte Carlo (HMC) as we found that to outperform MAP inference.\n",
    "\n",
    "We find that SAASBO performs well on problems with hundreds of dimensions. As we rely on HMC \n",
    "and in particular the No-U-Turn-Sampler (NUTS) for inference, the overhead of SAASBO scales \n",
    "cubically with the number of datapoints. Depending on the problem, using more than a few hundred\n",
    "evaluations may not be feasible as SAASBO is designed for problems with a limited evaluation budget.\n",
    "\n",
    "In general, we recommend using [Ax](https://ax.dev) for a simple BO setup like this one. See [here](https://ax.dev/tutorials/saasbo.html) for a SAASBO tutorial in Ax, which uses the Noisy Expected Improvement acquisition function. To customize the acquisition function used with SAASBO in Ax, see the [custom acquisition tutorial](./custom_acquisition), where adding `\\\"surrogate\\\": Surrogate(SaasFullyBayesianSingleTaskGP),` to the `model_kwargs` of `BOTORCH_MODULAR` step is sufficient to enable the SAAS model.\n",
    "\n",
    "[1]: [D. Eriksson, M. Jankowiak. High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces. Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence, 2021.](https://proceedings.mlr.press/v161/eriksson21a.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "customOutput": null,
    "executionStartTime": 1668653404823,
    "executionStopTime": 1668653404909,
    "hidden_ranges": [],
    "originalKey": "26933c08-82d6-439d-9fcb-6e358b080ab6",
    "requestMsgId": "1806f0c7-d668-4248-a390-14add9bcb451"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from botorch import fit_fully_bayesian_model_nuts\n",
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.models.fully_bayesian import SaasFullyBayesianSingleTaskGP\n",
    "from botorch.models.transforms import Standardize\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.test_functions import Branin\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653405125,
    "executionStopTime": 1668653405130,
    "hidden_ranges": [],
    "originalKey": "f1e3c7f0-1afc-42e2-af59-5f5fae755ce5",
    "requestMsgId": "068ddee5-939e-4f5b-8210-2f6a490f6c4e",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "tkwargs = {\n",
    "    \"device\": torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"dtype\": torch.double,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "08a3d790-52a5-4821-af21-1040f1a037f0",
    "showInput": false
   },
   "source": [
    "The time to fit the SAAS model can be decreased by lowering\n",
    "`WARMUP_STEPS` and `NUM_SAMPLES`. \n",
    "\n",
    "We recommend using 512 warmup steps and 256 samples when\n",
    "possible and to not use fewer than 256 warmup steps and 128 samples. By default, we only\n",
    "keep each 16th sample which with 256 samples results in 32 hyperparameter samples.\n",
    "\n",
    "To make this tutorial run faster we use 256 warmup steps and 128 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653405353,
    "executionStopTime": 1668653405445,
    "originalKey": "363224de-347c-46a7-9c84-970cbb8e825d",
    "requestMsgId": "09e1ff1f-9c11-4053-8123-08aa3397dfc1",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "WARMUP_STEPS = 256 if not SMOKE_TEST else 32\n",
    "NUM_SAMPLES = 128 if not SMOKE_TEST else 16\n",
    "THINNING = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "af8beafd-352c-421d-8797-7660ddfa39f3",
    "showInput": false
   },
   "source": [
    "## Simple model fitting\n",
    "We generate a simple function that only depends on the first parameter and show that the SAAS\n",
    "model sets all other lengthscales to large values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653405681,
    "executionStopTime": 1668653405771,
    "hidden_ranges": [],
    "originalKey": "f506aa6b-904c-4a7e-8a38-0443e983df06",
    "requestMsgId": "a6b6bfcd-c30c-4339-a342-02dd398a8274",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "train_X = torch.rand(10, 4, **tkwargs)\n",
    "test_X = torch.rand(5, 4, **tkwargs)\n",
    "train_Y = torch.sin(train_X[:, :1])\n",
    "test_Y = torch.sin(test_X[:, :1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "cc9314b1-f255-4f7d-9f6d-eb349b34805e",
    "showInput": false
   },
   "source": [
    "By default, we infer the unknown noise variance in the data. You can also pass in a known \n",
    "noise variance (`train_Yvar`) for each observation, which may be useful in cases where you for example\n",
    "know that the problem is noise-free and can then set the noise variance to a small value such as `1e-6`.\n",
    "\n",
    "In this case you can construct a model as follows:\n",
    "```\n",
    "gp = SaasFullyBayesianSingleTaskGP(train_X=train_X, train_Y=train_Y, train_Yvar=torch.full_like(train_Y, 1e-6))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653406085,
    "executionStopTime": 1668653471282,
    "hidden_ranges": [],
    "originalKey": "148855fb-cf0c-4fc5-8431-06a5e61c5da5",
    "requestMsgId": "0c13f0b6-28b9-43ea-8d1b-00871e5e4f02",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "gp = SaasFullyBayesianSingleTaskGP(\n",
    "    train_X=train_X, \n",
    "    train_Y=train_Y, \n",
    "    outcome_transform=Standardize(m=1)\n",
    ")\n",
    "fit_fully_bayesian_model_nuts(\n",
    "    gp,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    thinning=THINNING,\n",
    "    disable_progbar=True,\n",
    ")\n",
    "with torch.no_grad():\n",
    "    posterior = gp.posterior(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "5f4fa168-2662-499b-ac82-3ab122dfe2ad",
    "showInput": false
   },
   "source": [
    "Computing the median lengthscales over the MCMC dimensions makes it clear that the first feature has the smallest lengthscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653471605,
    "executionStopTime": 1668653471693,
    "hidden_ranges": [],
    "originalKey": "44a1f7c0-9649-4d89-8226-0405fdf88518",
    "requestMsgId": "e815926b-5a2d-4b78-8b89-3c0720e45592",
    "showInput": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.6589, 27.7498, 18.2926, 78.3324], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(gp.median_lengthscale.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "cf15a6ca-3377-40d1-9821-fad8f6600657",
    "showInput": false
   },
   "source": [
    "### Make predictions with the model\n",
    "\n",
    "In the next cell we show how to make predictions with the SAAS model. You compute the mean\n",
    "and variance for test points just like for any other BoTorch posteriors. Note that the mean \n",
    "and posterior will have an extra batch dimension at -3 that corresponds to the number of MCMC\n",
    "samples (which is 16 in this tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653471916,
    "executionStopTime": 1668653472023,
    "hidden_ranges": [],
    "originalKey": "898039a4-6ec8-46bd-a583-5a1614a3ccf6",
    "requestMsgId": "4328636f-fb02-44ee-8c48-842c3845297f",
    "showInput": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5, 1])\n",
      "torch.Size([8, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "print(posterior.mean.shape)\n",
    "print(posterior.variance.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "02b33f7f-4f31-432a-bac7-8cad1831e9a1",
    "showInput": false
   },
   "source": [
    "We also provide several convenience methods for computing different statistics over the MCMC samples:\n",
    "```\n",
    "mixture_mean = posterior.mixture_mean\n",
    "mixture_variance = posterior.mixture_variance\n",
    "mixture_quantile = posterior.quantile(q=0.95)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653472240,
    "executionStopTime": 1668653472326,
    "hidden_ranges": [],
    "originalKey": "b387d057-a497-401b-bfc2-ab427669c451",
    "requestMsgId": "64e0ee73-6ffd-4ad5-b9b2-bd9ea4e637ee",
    "showInput": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth:     tensor([0.5635, 0.1783, 0.3822, 0.3159, 0.0162], dtype=torch.float64)\n",
      "Mixture mean:     tensor([0.5554, 0.1787, 0.3755, 0.3142, 0.0193], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ground truth:     {test_Y.squeeze(-1)}\")\n",
    "print(f\"Mixture mean:     {posterior.mixture_mean.squeeze(-1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "executionStartTime": 1644277314184,
    "executionStopTime": 1644277314189,
    "hidden_ranges": [],
    "originalKey": "d9bec8be-2acd-40b8-aebb-612b62bbdfc3",
    "requestMsgId": "d9bec8be-2acd-40b8-aebb-612b62bbdfc3",
    "showInput": false
   },
   "source": [
    "## Optimize Branin embedded in a 50D space\n",
    "We take the standard 2D Branin problem and embed it in a 50D space. In particular,\n",
    "we let dimensions 0 and 1 correspond to the true dimensions. We will show that\n",
    "SAASBO is able to identify the important dimensions and efficiently optimize this function.\n",
    "We work with the domain $[0, 1]^d$ and unnormalize the inputs to the true domain of Branin \n",
    "before evaluating the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653472540,
    "executionStopTime": 1668653472545,
    "hidden_ranges": [],
    "originalKey": "15baa08e-ca35-4da7-a495-c63fe5d5779d",
    "requestMsgId": "6c3f8d91-9139-4c07-986f-77629b1887e5",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "branin = Branin().to(**tkwargs)\n",
    "\n",
    "\n",
    "def branin_emb(x):\n",
    "    \"\"\"x is assumed to be in [0, 1]^d\"\"\"\n",
    "    lb, ub = branin.bounds\n",
    "    return branin(lb + (ub - lb) * x[..., :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653472768,
    "executionStopTime": 1668653472776,
    "hidden_ranges": [],
    "originalKey": "98b6936b-2f06-4d1f-82c0-2f1bd660d0b2",
    "requestMsgId": "1b5baaf2-e690-4b4d-9011-b6124e083410",
    "showInput": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a total of 40 function evaluations\n"
     ]
    }
   ],
   "source": [
    "DIM = 30 if not SMOKE_TEST else 10\n",
    "\n",
    "# Evaluation budget\n",
    "N_INIT = 10\n",
    "N_ITERATIONS = 6 if not SMOKE_TEST else 1\n",
    "BATCH_SIZE = 5 if not SMOKE_TEST else 1\n",
    "print(f\"Using a total of {N_INIT + BATCH_SIZE * N_ITERATIONS} function evaluations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "27fd793f-18ee-49cb-9aa5-c8cd78b0b807",
    "showInput": false
   },
   "source": [
    "### Run the optimization\n",
    "We use 10 initial Sobol points followed by 10 iterations of BO using a batch size of 4, \n",
    "which results in a total of 50 function evaluations. As our goal is to minimize Branin, we flip\n",
    "the sign of the function values before fitting the SAAS model as the BoTorch acquisition\n",
    "functions assume maximization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668653473096,
    "executionStopTime": 1668655621405,
    "hidden_ranges": [],
    "originalKey": "269287e0-500f-474d-891a-5439487e9a77",
    "requestMsgId": "5117b535-1fe7-40be-9f68-361db9d9b51b",
    "showInput": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best initial point: 5.322\n",
      "1) New best: 2.545 @ [1.000, 0.148]\n",
      "3) New best: 1.945 @ [1.000, 0.203]\n"
     ]
    }
   ],
   "source": [
    "X = SobolEngine(dimension=DIM, scramble=True, seed=0).draw(N_INIT).to(**tkwargs)\n",
    "Y = branin_emb(X).unsqueeze(-1)\n",
    "print(f\"Best initial point: {Y.min().item():.3f}\")\n",
    "\n",
    "for i in range(N_ITERATIONS):\n",
    "    train_Y = -1 * Y  # Flip the sign since we want to minimize f(x)\n",
    "    gp = SaasFullyBayesianSingleTaskGP(\n",
    "        train_X=X,\n",
    "        train_Y=train_Y,\n",
    "        train_Yvar=torch.full_like(train_Y, 1e-6),\n",
    "        outcome_transform=Standardize(m=1),\n",
    "    )\n",
    "    fit_fully_bayesian_model_nuts(\n",
    "        gp,\n",
    "        warmup_steps=WARMUP_STEPS,\n",
    "        num_samples=NUM_SAMPLES,\n",
    "        thinning=THINNING,\n",
    "        disable_progbar=True,\n",
    "    )\n",
    "\n",
    "    EI = qExpectedImprovement(model=gp, best_f=train_Y.max())\n",
    "    candidates, acq_values = optimize_acqf(\n",
    "        EI,\n",
    "        bounds=torch.cat((torch.zeros(1, DIM), torch.ones(1, DIM))).to(**tkwargs),\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=10,\n",
    "        raw_samples=1024,\n",
    "    )\n",
    "\n",
    "    Y_next = torch.cat([branin_emb(x).unsqueeze(-1) for x in candidates]).unsqueeze(-1)\n",
    "    if Y_next.min() < Y.min():\n",
    "        ind_best = Y_next.argmin()\n",
    "        x0, x1 = candidates[ind_best, :2].tolist()\n",
    "        print(\n",
    "            f\"{i + 1}) New best: {Y_next[ind_best].item():.3f} @ \"\n",
    "            f\"[{x0:.3f}, {x1:.3f}]\"\n",
    "        )\n",
    "    X = torch.cat((X, candidates))\n",
    "    Y = torch.cat((Y, Y_next))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "a9704a99-0712-40bb-a263-6798e0925291",
    "showInput": false
   },
   "source": [
    "## Plot the results\n",
    "\n",
    "We can see that we were able to get close to the global optimium of $\\approx 0.398$ after 50 function evaluations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668655621761,
    "executionStopTime": 1668655621936,
    "hidden_ranges": [],
    "originalKey": "fd0d7aa7-8d55-4942-adc2-de356666ac84",
    "requestMsgId": "4024717d-fc5c-4939-90ce-fb24b3e06ea3",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "Y_np = Y.cpu().numpy()\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(np.minimum.accumulate(Y_np), color=\"b\", label=\"SAASBO\")\n",
    "ax.plot([0, len(Y_np)], [0.398, 0.398], \"--\", c=\"g\", lw=3, label=\"Optimal value\")\n",
    "ax.grid(True)\n",
    "ax.set_title(f\"Branin, D = {DIM}\", fontsize=20)\n",
    "ax.set_xlabel(\"Number of evaluations\", fontsize=20)\n",
    "ax.set_xlim([0, len(Y_np)])\n",
    "ax.set_ylabel(\"Best value found\", fontsize=20)\n",
    "ax.set_ylim([0, 8])\n",
    "ax.legend(fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "d81134ff-cec6-45cb-92bf-4170f428af40",
    "showInput": false
   },
   "source": [
    "## Predict on some test points\n",
    "We fit a model using the 50 datapoints collected by SAASBO and predict on 50 test \n",
    "points in order to see how well the SAAS model predicts out-of-sample.\n",
    "The plot shows the mean and a 95% confidence interval for each test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668655622271,
    "executionStopTime": 1668655822584,
    "hidden_ranges": [],
    "originalKey": "970977ea-ee5e-46eb-b500-683673ce723e",
    "requestMsgId": "2ae0c053-022f-4902-8bc5-b904bd85f90d",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "train_X = SobolEngine(dimension=DIM, scramble=True, seed=0).draw(50).to(**tkwargs)\n",
    "test_X = SobolEngine(dimension=DIM, scramble=True, seed=1).draw(50).to(**tkwargs)\n",
    "train_Y = branin_emb(train_X).unsqueeze(-1)\n",
    "test_Y = branin_emb(test_X).unsqueeze(-1)\n",
    "\n",
    "gp = SaasFullyBayesianSingleTaskGP(\n",
    "    train_X=train_X,\n",
    "    train_Y=train_Y,\n",
    "    train_Yvar=torch.full_like(train_Y, 1e-6),\n",
    "    outcome_transform=Standardize(m=1),\n",
    ")\n",
    "fit_fully_bayesian_model_nuts(\n",
    "    gp,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    thinning=THINNING,\n",
    "    disable_progbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668655921184,
    "executionStopTime": 1668655921625,
    "hidden_ranges": [],
    "originalKey": "25139c91-a34c-4fa8-808f-70c1cf6952fd",
    "requestMsgId": "ad9413e7-09aa-47f5-b435-bf37cf0180d1",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    posterior = gp.posterior(test_X)\n",
    "median = posterior.quantile(value=torch.tensor([0.5], **tkwargs))\n",
    "q1 = posterior.quantile(value=torch.tensor([0.025], **tkwargs))\n",
    "q2 = posterior.quantile(value=torch.tensor([0.975], **tkwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668655923525,
    "executionStopTime": 1668655923743,
    "hidden_ranges": [],
    "originalKey": "39163b27-e252-4244-9712-f52503e00f74",
    "requestMsgId": "7c819fcc-5f74-48b1-9fd4-286839fdd0b6",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "ax.plot([0, 80], [0, 80], \"b--\", lw=2)\n",
    "\n",
    "yerr1, yerr2 = median - q1, q2 - median\n",
    "yerr = torch.cat((yerr1.unsqueeze(0), yerr2.unsqueeze(0)), dim=0).squeeze(-1)\n",
    "markers, caps, bars = ax.errorbar(\n",
    "    test_Y.squeeze(-1).cpu(),\n",
    "    median.squeeze(-1).cpu(),\n",
    "    yerr=yerr.cpu(),\n",
    "    fmt=\".\",\n",
    "    capsize=4,\n",
    "    elinewidth=2.0,\n",
    "    ms=14,\n",
    "    c=\"k\",\n",
    "    ecolor=\"gray\",\n",
    ")\n",
    "ax.set_xlim([0, 80])\n",
    "ax.set_ylim([0, 80])\n",
    "[bar.set_alpha(0.8) for bar in bars]\n",
    "[cap.set_alpha(0.8) for cap in caps]\n",
    "ax.set_xlabel(\"True value\", fontsize=20)\n",
    "ax.set_ylabel(\"Predicted value\", fontsize=20)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "hidden_ranges": [],
    "originalKey": "34e976cd-7d09-40d2-8987-aecdefa7c0fd",
    "requestMsgId": "34e976cd-7d09-40d2-8987-aecdefa7c0fd",
    "showInput": false
   },
   "source": [
    "## Look a the lengthscales from the final model\n",
    "\n",
    "As SAASBO places strong priors on the inverse lengthscales, we only expect parameters \n",
    "0 and 1 to be identified as important by the model since the other parameters have no effect.\n",
    "We can confirm that this is the case below as the lengthscales of parameters 0 and 1 are \n",
    "small with all other lengthscales being large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "customInput": null,
    "customOutput": null,
    "executionStartTime": 1668655927129,
    "executionStopTime": 1668655927142,
    "hidden_ranges": [],
    "originalKey": "33147b57-ea6b-4c67-9c7d-796bb54d5c84",
    "requestMsgId": "b32e63df-16ee-45f1-af94-7f6f4bb78173",
    "showInput": true
   },
   "outputs": [],
   "source": [
    "median_lengthscales = gp.median_lengthscale\n",
    "for i in median_lengthscales.argsort()[:10]:\n",
    "    print(f\"Parameter {i:2}) Median lengthscale = {median_lengthscales[i].item():.2e}\")"
   ]
  }
 ],
 "metadata": {
  "captumWidgetMessage": {},
  "dataExplorerConfig": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "outputWidgetContext": {}
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
