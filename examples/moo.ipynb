{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batched Bayesian optimization with EI on Hartmann6\n",
    "\n",
    "This example walks through how to perform batched Bayesian optimization (BO) on the 6-dimensional synthetic test function 'Hartmann6' with noiseless observations in botorch. We first set up the device and data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up device and data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "dtype = torch.float\n",
    "initial_seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hartmann6 optimization problem is to minimize\n",
    "\n",
    "$$f(x) = -\\sum_{i=1}^4 \\alpha_i \\exp \\left( -\\sum_{j=1}^6 A_{ij} (x_j - P_{ij})^2  \\right),$$\n",
    "\n",
    "over $x \\in [0,1]^6$. The values of $\\alpha_i$, $A_{ij}$, and $P_{ij}$ can be found in `botorch/test_functions/hartmann6.py`. Since botorch assumes a maximization problem, we will attempt to maximize $-f(x)$ to achieve $\\max_{x} -f(x) = 3.32237$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_MAXIMIZER = -2.903534\n",
    "GLOBAL_MAXIMUM = 39.166166\n",
    "\n",
    "\n",
    "def neg_styblinski_tang(X: Tensor) -> Tensor:\n",
    "    \"\"\"Negative Styblinski-Tang test function.\n",
    "\n",
    "    d-dimensional function (usually evaluated on the hypercube `[-5, 5]^d`):\n",
    "\n",
    "        H(x) = 0.5 * sum_{i=1}^d (x_i^4 - 16 * x_i^2 + 5 * x_i)\n",
    "\n",
    "    H has a single global mininimum `H(z) = -39.166166 * d` at\n",
    "    `z = [-2.903534]^d`\n",
    "\n",
    "    Args:\n",
    "        X: A Tensor of size `d` or `k x d` (`k` batch evaluations)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: `-H(X)`, the negative value of the standard Styblinski-Tang\n",
    "            function.\n",
    "    \"\"\"\n",
    "    batch = X.ndimension() > 1\n",
    "    X = X if batch else X.unsqueeze(0)\n",
    "    H = 0.5 * (X ** 4 - 16 * X ** 2 + 5 * X).sum(dim=1)\n",
    "    result = -H\n",
    "    return result if batch else result.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up oracle (i.e., the function to optimize) and define a random point sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions.hartmann6 import neg_hartmann6, GLOBAL_MAXIMUM\n",
    "from botorch.acquisition.batch_utils import batch_mode_transform\n",
    "\n",
    "DATA_DIM = 6  # the dimension of x\n",
    "MAX_VAL = GLOBAL_MAXIMUM\n",
    "\n",
    "def oracle(X):\n",
    "    \"\"\"Oracle function for generating observations, where X is a `b x q x 6` tensor.\n",
    "    Some shape manipulations are performed here to adhere with neg_hartmann6, which accepts\n",
    "    tensors of shape `b' x 6`.\n",
    "    \"\"\"\n",
    "    q = X.shape[-2]\n",
    "    Y = neg_hartmann6(X.view(-1, DATA_DIM))\n",
    "    return Y.reshape((-1, q))\n",
    "\n",
    "def gen_x(num_samples, q=1):\n",
    "    \"\"\"Generate random points in the unit cube [0, 1]^6\"\"\"\n",
    "    return torch.rand(num_samples, q, DATA_DIM, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32237\n"
     ]
    }
   ],
   "source": [
    "print(GLOBAL_MAXIMUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import a basic GP model, acquisition functions, and other helper functions\n",
    "\n",
    "This is the model specification of a simple GP model in gpytorch, using a constant mean, RBF Kernel with Automatic Relevance Discovery (ARD). The qEI acquisition function and several other helper functions are also imported here. We use $10$ inital points per trial (sampled using `gen_x`), a batch size of $q=5$, and $20$ batches (or iterations) per trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP\n",
    "from botorch.acquisition.batch_modules import qExpectedImprovement\n",
    "from botorch.optim import initialize_q_batch_simple\n",
    "from botorch.benchmarks.optimize import optimize_from_initialization\n",
    "from botorch import fit_model\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "import time\n",
    "\n",
    "INITIAL_POINTS = 10  # The number of initial random samples to take at the beginning of each trial\n",
    "BATCH_SIZE = 5  # The batch size, q\n",
    "N_BATCH = 30  # The number of batches to test for each trial\n",
    "N_TRIALS = 20  # The number of independent trials (N_TRIALS of N_BATCH iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set some optimization-related parameters. We use $1000$ (quasi)-Monte Carlo samples to approximate the acquisition function and $40$ random restarts chosen from $100$ initial candidates at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_SAMPLES = 100  # The number of Monte Carlo samples used to estimate acquisition functions\n",
    "FIT_OPTIMIZER_ITER = 200  # Number of iterations used to fit model\n",
    "ACQ_OPTIMIZER_ITER = 200  # Number of iterations used to optimize acquisition function\n",
    "N_RESTART_CANDIDATES = 100  # Number of random from which to select restart initial points\n",
    "N_RESTARTS = 20  # Number of restarts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a helper function that performs the essential BO step\n",
    "The Bayesian optimization 'loop' for a batch size of $q$ simply iterates the following steps: (1) given a surrogate model, choose a batch of points $\\{x_1, x_2, \\ldots x_q\\}$, (2) observe $f(x)$ for each $x$ in the batch, and (3) update the surrogate model. Much of the work resides in (1), where the batch is selected by optimizing an acquisition function, q-EI. The helper function below takes an acquisition function as an argument, optimizes it, and returns the batch $\\{x_1, x_2, \\ldots x_q\\}$ along with the observed function values. It also includes logic for selecting restart candidates based on the heuristic `initialize_q_batch_simple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_acq_and_return_observation(acq_func):\n",
    "    \"\"\"Generates restart conditions, optimizes the acquisition function, and returns\n",
    "        a new candidate and a noisy observation at that candidate.\n",
    "    \"\"\"\n",
    "    # Generate a pool of restart candidates and evaluate their acquisition values \n",
    "    X = gen_x(N_RESTART_CANDIDATES, q=BATCH_SIZE)\n",
    "    Y = acq_func(X)\n",
    "    \n",
    "    # Use a heuristic to select N_RESTART points from the pool of restart candidates\n",
    "    initial_candidates = initialize_q_batch_simple(X=X, Y=Y, n=N_RESTARTS)\n",
    "    \n",
    "    # Optimize\n",
    "    candidates = optimize_from_initialization(\n",
    "        initial_candidates=initial_candidates,\n",
    "        acq_func=acq_func,\n",
    "        lower_bounds=0,\n",
    "        upper_bounds=1,\n",
    "        candidate_optim_options={\"maxiter\": ACQ_OPTIMIZER_ITER},\n",
    "    )\n",
    "\n",
    "    # Fetch the new values \n",
    "    new_x = candidates.detach().squeeze()\n",
    "    new_y = oracle(new_x).squeeze()\n",
    "    return new_x, new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the BO loop with q-EI\n",
    "\n",
    "We are now ready to run the full BO loop, repeated N_TRIALS = 20 times. In each trial, we draw initial points using ```gen_x``` and then fit the ```SingleTaskGP``` using training data derived from the initial points and noiseless evaluations of $-f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 of 20\n",
      "Initial sample, best_value: 1.03\n",
      "Batch  5: best_value (EI, random) = (2.20, 1.57)\n",
      "Batch 10: best_value (EI, random) = (2.62, 1.57)\n",
      "Batch 15: best_value (EI, random) = (2.89, 1.57)\n",
      "Batch 20: best_value (EI, random) = (2.89, 1.57)\n",
      "Batch 25: best_value (EI, random) = (2.98, 1.57)\n",
      "Batch 30: best_value (EI, random) = (2.98, 2.10)\n",
      "Trial 2 of 20\n",
      "Initial sample, best_value: 0.236\n",
      "Batch  5: best_value (EI, random) = (1.17, 1.43)\n",
      "Batch 10: best_value (EI, random) = (1.83, 1.43)\n",
      "Batch 15: best_value (EI, random) = (1.85, 2.04)\n",
      "Batch 20: best_value (EI, random) = (2.59, 2.04)\n",
      "Batch 25: best_value (EI, random) = (2.64, 2.04)\n",
      "Batch 30: best_value (EI, random) = (2.64, 2.04)\n",
      "Trial 3 of 20\n",
      "Initial sample, best_value: 0.575\n",
      "Batch  5: best_value (EI, random) = (2.08, 0.85)\n",
      "Batch 10: best_value (EI, random) = (2.18, 0.86)\n",
      "Batch 15: best_value (EI, random) = (3.21, 1.87)\n",
      "Batch 20: best_value (EI, random) = (3.21, 1.87)\n",
      "Batch 25: best_value (EI, random) = (3.21, 1.87)\n",
      "Batch 30: best_value (EI, random) = (3.21, 1.87)\n",
      "Trial 4 of 20\n",
      "Initial sample, best_value: 0.53\n",
      "Batch  5: best_value (EI, random) = (2.29, 0.90)\n",
      "Batch 10: best_value (EI, random) = (2.61, 1.04)\n",
      "Batch 15: best_value (EI, random) = (2.61, 1.04)\n",
      "Batch 20: best_value (EI, random) = (2.61, 1.53)\n",
      "Batch 25: best_value (EI, random) = (2.61, 1.56)\n",
      "Batch 30: best_value (EI, random) = (2.61, 1.56)\n",
      "Trial 5 of 20\n",
      "Initial sample, best_value: 0.786\n",
      "Batch  5: best_value (EI, random) = (1.90, 1.54)\n",
      "Batch 10: best_value (EI, random) = (1.90, 1.54)\n",
      "Batch 15: best_value (EI, random) = (2.16, 2.20)\n",
      "Batch 20: best_value (EI, random) = (3.01, 2.20)\n",
      "Batch 25: best_value (EI, random) = (3.01, 2.20)\n",
      "Batch 30: best_value (EI, random) = (3.01, 2.20)\n",
      "Trial 6 of 20\n",
      "Initial sample, best_value: 0.89\n",
      "Batch  5: best_value (EI, random) = (2.77, 2.55)\n",
      "Batch 10: best_value (EI, random) = (2.94, 2.55)\n",
      "Batch 15: best_value (EI, random) = (3.15, 2.55)\n",
      "Batch 20: best_value (EI, random) = (3.15, 2.55)\n",
      "Batch 25: best_value (EI, random) = (3.15, 2.55)\n",
      "Batch 30: best_value (EI, random) = (3.15, 2.55)\n",
      "Trial 7 of 20\n",
      "Initial sample, best_value: 1.01\n",
      "Batch  5: best_value (EI, random) = (2.79, 1.59)\n",
      "Batch 10: best_value (EI, random) = (2.99, 1.59)\n",
      "Batch 15: best_value (EI, random) = (2.99, 1.59)\n",
      "Batch 20: best_value (EI, random) = (2.99, 1.59)\n",
      "Batch 25: best_value (EI, random) = (2.99, 1.59)\n",
      "Batch 30: best_value (EI, random) = (3.05, 1.59)\n",
      "Trial 8 of 20\n",
      "Initial sample, best_value: 0.406\n",
      "Batch  5: best_value (EI, random) = (1.45, 0.84)\n",
      "Batch 10: best_value (EI, random) = (2.28, 1.98)\n",
      "Batch 15: best_value (EI, random) = (2.52, 2.73)\n",
      "Batch 20: best_value (EI, random) = (2.85, 2.73)\n",
      "Batch 25: best_value (EI, random) = (3.04, 2.73)\n",
      "Batch 30: best_value (EI, random) = (3.04, 2.73)\n",
      "Trial 9 of 20\n",
      "Initial sample, best_value: 0.694\n",
      "Batch  5: best_value (EI, random) = (2.65, 0.95)\n",
      "Batch 10: best_value (EI, random) = (2.79, 1.23)\n",
      "Batch 15: best_value (EI, random) = (2.93, 1.23)\n",
      "Batch 20: best_value (EI, random) = (2.93, 1.23)\n",
      "Batch 25: best_value (EI, random) = (2.93, 1.80)\n",
      "Batch 30: best_value (EI, random) = (2.93, 1.80)\n",
      "Trial 10 of 20\n",
      "Initial sample, best_value: 0.636\n",
      "Batch  5: best_value (EI, random) = (1.53, 1.27)\n",
      "Batch 10: best_value (EI, random) = (1.84, 2.06)\n",
      "Batch 15: best_value (EI, random) = (2.88, 2.06)\n",
      "Batch 20: best_value (EI, random) = (2.88, 2.06)\n",
      "Batch 25: best_value (EI, random) = (2.88, 2.06)\n",
      "Batch 30: best_value (EI, random) = (2.88, 2.06)\n",
      "Trial 11 of 20\n",
      "Initial sample, best_value:  1.1\n",
      "Batch  5: best_value (EI, random) = (2.32, 1.81)\n",
      "Batch 10: best_value (EI, random) = (2.32, 1.81)\n",
      "Batch 15: best_value (EI, random) = (2.71, 1.81)\n",
      "Batch 20: best_value (EI, random) = (2.71, 1.81)\n",
      "Batch 25: best_value (EI, random) = (2.71, 1.81)\n",
      "Batch 30: best_value (EI, random) = (2.71, 2.21)\n",
      "Trial 12 of 20\n",
      "Initial sample, best_value:  1.1\n",
      "Batch  5: best_value (EI, random) = (2.75, 1.13)\n",
      "Batch 10: best_value (EI, random) = (3.06, 1.13)\n",
      "Batch 15: best_value (EI, random) = (3.06, 2.00)\n",
      "Batch 20: best_value (EI, random) = (3.09, 2.00)\n",
      "Batch 25: best_value (EI, random) = (3.18, 2.70)\n",
      "Batch 30: best_value (EI, random) = (3.18, 2.70)\n",
      "Trial 13 of 20\n",
      "Initial sample, best_value: 1.31\n",
      "Batch  5: best_value (EI, random) = (2.87, 1.59)\n",
      "Batch 10: best_value (EI, random) = (2.87, 2.07)\n",
      "Batch 15: best_value (EI, random) = (2.87, 2.07)\n",
      "Batch 20: best_value (EI, random) = (3.11, 2.38)\n",
      "Batch 25: best_value (EI, random) = (3.11, 2.38)\n",
      "Batch 30: best_value (EI, random) = (3.11, 2.55)\n",
      "Trial 14 of 20\n",
      "Initial sample, best_value: 2.49\n",
      "Batch  5: best_value (EI, random) = (3.05, 2.49)\n",
      "Batch 10: best_value (EI, random) = (3.05, 2.49)\n",
      "Batch 15: best_value (EI, random) = (3.05, 2.49)\n",
      "Batch 20: best_value (EI, random) = (3.05, 2.49)\n",
      "Batch 25: best_value (EI, random) = (3.05, 2.49)\n",
      "Batch 30: best_value (EI, random) = (3.05, 2.49)\n",
      "Trial 15 of 20\n",
      "Initial sample, best_value: 1.36\n",
      "Batch  5: best_value (EI, random) = (2.63, 1.36)\n",
      "Batch 10: best_value (EI, random) = (2.79, 1.36)\n",
      "Batch 15: best_value (EI, random) = (2.79, 1.36)\n",
      "Batch 20: best_value (EI, random) = (2.79, 1.36)\n",
      "Batch 25: best_value (EI, random) = (2.85, 1.36)\n",
      "Batch 30: best_value (EI, random) = (2.85, 1.36)\n",
      "Trial 16 of 20\n",
      "Initial sample, best_value: 0.209\n",
      "Batch  5: best_value (EI, random) = (1.70, 0.79)\n",
      "Batch 10: best_value (EI, random) = (2.12, 0.90)\n",
      "Batch 15: best_value (EI, random) = (2.83, 0.99)\n",
      "Batch 20: best_value (EI, random) = (3.10, 1.12)\n",
      "Batch 25: best_value (EI, random) = (3.10, 1.82)\n",
      "Batch 30: best_value (EI, random) = (3.10, 1.82)\n",
      "Trial 17 of 20\n",
      "Initial sample, best_value: 1.03\n",
      "Batch  5: best_value (EI, random) = (1.83, 1.03)\n",
      "Batch 10: best_value (EI, random) = (3.07, 1.03)\n",
      "Batch 15: best_value (EI, random) = (3.20, 2.08)\n",
      "Batch 20: best_value (EI, random) = (3.20, 2.08)\n",
      "Batch 25: best_value (EI, random) = (3.20, 2.08)\n",
      "Batch 30: best_value (EI, random) = (3.20, 2.67)\n",
      "Trial 18 of 20\n",
      "Initial sample, best_value: 0.505\n",
      "Batch  5: best_value (EI, random) = (2.18, 2.03)\n",
      "Batch 10: best_value (EI, random) = (2.31, 2.03)\n",
      "Batch 15: best_value (EI, random) = (2.79, 2.30)\n",
      "Batch 20: best_value (EI, random) = (2.79, 2.30)\n",
      "Batch 25: best_value (EI, random) = (2.79, 2.30)\n",
      "Batch 30: best_value (EI, random) = (2.79, 2.30)\n",
      "Trial 19 of 20\n",
      "Initial sample, best_value: 1.24\n",
      "Batch  5: best_value (EI, random) = (2.14, 1.40)\n",
      "Batch 10: best_value (EI, random) = (2.14, 1.40)\n",
      "Batch 15: best_value (EI, random) = (2.14, 1.40)\n",
      "Batch 20: best_value (EI, random) = (2.64, 1.40)\n",
      "Batch 25: best_value (EI, random) = (2.64, 1.40)\n",
      "Batch 30: best_value (EI, random) = (2.93, 1.40)\n",
      "Trial 20 of 20\n",
      "Initial sample, best_value: 1.09\n",
      "Batch  5: best_value (EI, random) = (2.55, 1.32)\n",
      "Batch 10: best_value (EI, random) = (2.55, 1.32)\n",
      "Batch 15: best_value (EI, random) = (2.76, 1.35)\n",
      "Batch 20: best_value (EI, random) = (2.76, 1.91)\n",
      "Batch 25: best_value (EI, random) = (2.76, 1.91)\n",
      "Batch 30: best_value (EI, random) = (2.79, 1.91)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(initial_seed)\n",
    "best_observed_ei_all = []\n",
    "best_random_all = []\n",
    "cpu_time_all = []\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for trial in range(N_TRIALS):\n",
    "    \n",
    "    print(f\"Trial {trial + 1} of {N_TRIALS}\")\n",
    "    best_observed_ei = []\n",
    "    best_random = []\n",
    "    cpu_time = []\n",
    "    \n",
    "    # Initial random observations are the same for both acquisition functions\n",
    "    train_x_ei = gen_x(INITIAL_POINTS).squeeze()\n",
    "    train_y_ei = oracle(train_x_ei).squeeze()\n",
    "    \n",
    "    # Initialize models\n",
    "    model = SingleTaskGP(train_X=train_x_ei, train_Y=train_y_ei)\n",
    "    model = model.to(device=device, dtype=dtype)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    # Keep track of the best observed point at each iteration\n",
    "    best_value_ei = oracle(train_x_ei).max().item()\n",
    "    best_observed_ei.append(best_value_ei)\n",
    "    best_random.append(best_value_ei)\n",
    "    \n",
    "    print(f\"Initial sample, best_value: {best_value_ei:4.3}\")\n",
    "\n",
    "    # Run N_BATCH rounds of BO after the initial random batch\n",
    "    for iteration in range(N_BATCH):\n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Fit models\n",
    "        fit_model(mll, options={\"maxiter\": FIT_OPTIMIZER_ITER, \"verbose\": True})\n",
    "        \n",
    "        # Define the acquisition function\n",
    "        qEI = qExpectedImprovement(model, best_f=best_value_ei, mc_samples=MC_SAMPLES, qmc=True)\n",
    "\n",
    "        # Optimize and get observations\n",
    "        new_x_ei, new_y_ei = optimize_acq_and_return_observation(qEI)\n",
    "        # Update training points\n",
    "        train_x_ei = torch.cat((train_x_ei, new_x_ei))\n",
    "        train_y_ei = torch.cat((train_y_ei, new_y_ei))\n",
    "                        \n",
    "        # Get the new best observed value\n",
    "        best_value_ei = oracle(train_x_ei).max().item()\n",
    "        best_observed_ei.append(best_value_ei)\n",
    "        \n",
    "        # Get the new best value if random sampling is used\n",
    "        next_random_best = oracle(gen_x(BATCH_SIZE)).max().item()\n",
    "        best_random.append(max(best_random[-1], next_random_best))\n",
    "        \n",
    "        # Reinitialize the model\n",
    "        model.reinitialize(train_X=train_x_ei, train_Y=train_y_ei, keep_params=True)        \n",
    "        \n",
    "        t1 = time.time()\n",
    "        cpu_time.append(t1-t0)\n",
    "        \n",
    "        if (iteration+1) % 5 == 0:\n",
    "            print(f\"Batch {iteration+1:2}: best_value (EI, random) = ({best_value_ei:4.2f}, {max(best_random):4.2f})\")\n",
    "    \n",
    "    best_observed_ei_all.append(best_observed_ei)\n",
    "    best_random_all.append(best_random)\n",
    "    cpu_time_all.append(cpu_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c79dba385002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_BATCH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "iters = np.arange(N_BATCH+1)\n",
    "y_ei = np.asarray(best_observed_ei_all)\n",
    "y_rnd = np.asarray(best_random_all)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.errorbar(iters, y_ei.mean(axis=0), yerr=1.96*y_ei.std(axis=0)/np.sqrt(N_TRIALS), label=\"qEI\", linewidth=1.5)\n",
    "ax.errorbar(iters, y_rnd.mean(axis=0), yerr=1.96*y_rnd.std(axis=0)/np.sqrt(N_TRIALS), label=\"random\", linewidth=1.5)\n",
    "plt.plot([0, N_BATCH], [MAX_VAL]*2, 'k', label=\"true objective\", linewidth=2)\n",
    "ax.set_ylim(bottom=0.5)\n",
    "ax.set(xlabel='number of batches', ylabel='best objective value')\n",
    "ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.relaxed_bernoulli import RelaxedBernoulli, LogitRelaxedBernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    " m = RelaxedBernoulli(torch.tensor([2.2]),torch.tensor([0.1, 0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5840, 0.8825])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_samples = torch.rand(1)\n",
    "r = m.rsample()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(r.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": [],
  "anp_cloned_from": {
   "notebook_id": "327801827863318",
   "revision_id": "2483261731900726"
  },
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "disseminate_notebook_id": {
   "notebook_id": "2291093217619943"
  },
  "disseminate_notebook_info": {
   "bento_version": "20190304-030226",
   "description": "",
   "hide_code": false,
   "hipster_group": "",
   "kernel_build_info": {
    "error": "The file located at '/data/users/drjiang/fbsource/fbcode/bento/kernels/local/ae_lazarus/TARGETS' could not be found."
   },
   "no_uii": true,
   "notebook_number": "70442",
   "others_can_edit": false,
   "revision_id": "2572563962772051",
   "tags": "",
   "tasks": "",
   "title": "qEI_Hartmann6_noiseless"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
